{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "217af61d",
   "metadata": {},
   "source": [
    "# Paralelismo y Concurrencia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a9eece",
   "metadata": {},
   "source": [
    "### Cores vs Threads\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8def6514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cores disponibles: 10\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "cores = mp.cpu_count()\n",
    "print(f'Cores disponibles: {cores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed028fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar librería ('!' hace que la celda ejecute bash)\n",
    "# !pip install psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b4a675f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psutil==7.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip freeze | grep psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f4c179f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cores físicos: 10\n",
      "Cores lógicos: 10\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "physical_cores = psutil.cpu_count(logical=False)\n",
    "logical_cores = psutil.cpu_count(logical=True)\n",
    "\n",
    "print(f'Cores físicos: {physical_cores}')\n",
    "print(f'Cores lógicos: {logical_cores}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9af5624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hyperthreading NO disponible :(\n"
     ]
    }
   ],
   "source": [
    "if logical_cores > physical_cores:\n",
    "    print('Hyperthreading disponible...')\n",
    "else:\n",
    "    print('Hyperthreading NO disponible :(')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a132ccab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recomendación:\n",
      "- CPU-bound (multiprocessing): 10 workers\n",
      "- I/O-bound (threading): 40-80 workers\n"
     ]
    }
   ],
   "source": [
    "print(f'Recomendación:')\n",
    "print(f'- CPU-bound (multiprocessing): {physical_cores} workers')\n",
    "print(f'- I/O-bound (threading): {logical_cores * 4}-{logical_cores * 8} workers')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdb7c771",
   "metadata": {},
   "source": [
    "### Ley de Amdahl\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b2f706",
   "metadata": {},
   "source": [
    "Fórmula:\n",
    "\n",
    "Speedup = 1 / [(1 - P) + (P / N)]\n",
    "\n",
    "Donde:\n",
    "- P = proporción del programa que puede paralelizarse (0 a 1)\n",
    "- N = número de procesadores\n",
    "- (1 - P) = proporción serial (no paralelizable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb1ba2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed up teórico: 3.08\n",
      "\n",
      "Tiempo de ejecución serial: 40s\n",
      "Tiempo de ejecución con paralelismo: 13.0s\n"
     ]
    }
   ],
   "source": [
    "P = 0.9\n",
    "N = 4\n",
    "\n",
    "speed_up = 1 / ((1 - P) + (P / N))\n",
    "print(f'Speed up teórico: {round(speed_up, 2)}')\n",
    "\n",
    "# Estimación de tiempos\n",
    "seconds = 40\n",
    "print(f'\\nTiempo de ejecución serial: {seconds}s')\n",
    "print(f'Tiempo de ejecución con paralelismo: {round(seconds/speed_up, 2)}s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b7c162",
   "metadata": {},
   "source": [
    "### Multithreading (concurrencia)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9fdc0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff361c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Definir función que ejecutará cada thread\n",
    "\n",
    "def worker_task(id_worker, seconds):\n",
    "\n",
    "    print(f'[Thread {id_worker}] Iniciando tarea...')\n",
    "    time.sleep(seconds)  # Simula operación I/O (espera)\n",
    "    print(f'[Thread {id_worker}] Tarea completada después de {seconds}s')\n",
    "    return f'Resultado del thread {id_worker}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f0da59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Crear y ejecutar threads\n",
    "\n",
    "def threads_manual():\n",
    "    \n",
    "    # Lista para almacenar los threads\n",
    "    threads = []\n",
    "    \n",
    "    # Datos de entrada\n",
    "    tareas = [\n",
    "        (1, 2),  # (id_worker, seconds)\n",
    "        (2, 1),\n",
    "        (3, 3),\n",
    "        (4, 1),\n",
    "    ]\n",
    "    \n",
    "    inicio = time.time()\n",
    "    \n",
    "    # Crear y ejecutar threads\n",
    "    for id_worker, seconds in tareas:\n",
    "        # Crear thread\n",
    "        t = threading.Thread(\n",
    "            target=worker_task,       # Función a ejecutar\n",
    "            args=(id_worker, seconds) # Argumentos de la función\n",
    "        )\n",
    "        threads.append(t)\n",
    "        t.start()  # Iniciar el thread\n",
    "    \n",
    "    print(f'\\n{len(threads)} threads iniciados\\n')\n",
    "    \n",
    "    # Esperar a que todos terminen (JOIN)\n",
    "    for t in threads:\n",
    "        t.join()  # Bloquea hasta que el thread termine\n",
    "    \n",
    "    fin = time.time()\n",
    "    \n",
    "    print(f'\\nTodos los threads completados')\n",
    "    print(f'Tiempo total: {fin - inicio:.2f}s')\n",
    "    print(f'Tiempo si fuera serial: {sum(s for _, s in tareas)}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f05bbe36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread 1] Iniciando tarea...\n",
      "[Thread 2] Iniciando tarea...\n",
      "[Thread 3] Iniciando tarea...\n",
      "[Thread 4] Iniciando tarea...\n",
      "\n",
      "4 threads iniciados\n",
      "\n",
      "[Thread 2] Tarea completada después de 1s\n",
      "[Thread 4] Tarea completada después de 1s\n",
      "[Thread 1] Tarea completada después de 2s\n",
      "[Thread 3] Tarea completada después de 3s\n",
      "\n",
      "Todos los threads completados\n",
      "Tiempo total: 3.01s\n",
      "Tiempo si fuera serial: 7s\n"
     ]
    }
   ],
   "source": [
    "threads_manual()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd942e53",
   "metadata": {},
   "source": [
    "Versión moderna con pool (no manual):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00e469fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b86cb816",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worker_task(id_worker, seconds):\n",
    "\n",
    "    print(f'[Thread {id_worker}] Procesando...')\n",
    "    time.sleep(seconds)\n",
    "    return f'Resultado {id_worker}'\n",
    "\n",
    "\n",
    "def example_threadpool():\n",
    "\n",
    "    tareas = [\n",
    "        (1, 2),  # (id_worker, seconds)\n",
    "        (2, 1),\n",
    "        (3, 3),\n",
    "        (4, 1),\n",
    "        (5, 1)\n",
    "    ]\n",
    "    max_workers = 5  # Número de threads simultáneos\n",
    "    \n",
    "    inicio = time.time()\n",
    "    \n",
    "    # Context manager - se encarga del join automáticamente\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = []\n",
    "        for id_worker, seconds in tareas:\n",
    "            future = executor.submit(worker_task, id_worker, seconds)\n",
    "            futures.append(future)\n",
    "        \n",
    "        # Recolectar resultados conforme terminan\n",
    "        print('\\nResultados (en orden de finalización):')\n",
    "        for future in as_completed(futures):\n",
    "            resultado = future.result()  # Obtener resultado\n",
    "            print(f'{resultado}')\n",
    "    \n",
    "    fin = time.time()\n",
    "    print(f'\\nTiempo total: {fin - inicio:.2f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bd4b9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Thread 1] Procesando...\n",
      "[Thread 2] Procesando...\n",
      "[Thread 3] Procesando...\n",
      "[Thread 4] Procesando...\n",
      "[Thread 5] Procesando...\n",
      "\n",
      "Resultados (en orden de finalización):\n",
      "Resultado 2\n",
      "Resultado 5\n",
      "Resultado 4\n",
      "Resultado 1\n",
      "Resultado 3\n",
      "\n",
      "Tiempo total: 3.00s\n"
     ]
    }
   ],
   "source": [
    "example_threadpool()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d6b63f",
   "metadata": {},
   "source": [
    "### Multiprocessing (paralelismo)\n",
    "--- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a9a1002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp\n",
    "import random\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "417ea9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Definir función que ejecutará cada proceso\n",
    "\n",
    "def search_in_chunk(chunk, target, chunk_id):\n",
    "    \n",
    "    for value in chunk:\n",
    "        if value == target:\n",
    "            return (True, chunk_id)\n",
    "        \n",
    "    return (False, chunk_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5b4adac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Crear y ejecutar procesos\n",
    "\n",
    "\n",
    "def worker(chunk_tuple, resultado_queue):\n",
    "    chunk, target, chunk_id = chunk_tuple\n",
    "    resultado = search_in_chunk(chunk, target, chunk_id)\n",
    "    resultado_queue.put(resultado)\n",
    "\n",
    "\n",
    "def parallel_search(data, target, n_cores):\n",
    "   \n",
    "    # Dividir datos en chunks\n",
    "    chunk_size = len(data) // n_cores\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(n_cores):\n",
    "        start = i * chunk_size\n",
    "        end = start + chunk_size if i < n_cores - 1 else len(data)\n",
    "        # each chunk is (chunk_data, target, chunk_id)\n",
    "        chunks.append((data[start:end], target, i))\n",
    "    \n",
    "    # Crear procesos manualmente\n",
    "    processes = []\n",
    "    queue = mp.Queue()\n",
    "    \n",
    "    # [worker]\n",
    "    # def worker(chunk_tuple, resultado_queue):\n",
    "    #     chunk, target, chunk_id = chunk_tuple\n",
    "    #     resultado = search_in_chunk(chunk, target, chunk_id)\n",
    "    #     resultado_queue.put(resultado)\n",
    "\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Iniciar procesos\n",
    "    for chunk_data in chunks:\n",
    "        p = mp.Process(target=worker, args=(chunk_data, queue))\n",
    "        p.start()\n",
    "        processes.append(p)\n",
    "    \n",
    "    # Esperar a que terminen\n",
    "    for p in processes:\n",
    "        p.join()\n",
    "    \n",
    "    # Recolectar resultados\n",
    "    results = []\n",
    "    while not queue.empty():\n",
    "        results.append(queue.get())\n",
    "    \n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    # Mostrar resultados\n",
    "    for found, chunk_id in results:\n",
    "        if found:\n",
    "            print(f'Valor {target} encontrado en chunk {chunk_id}')\n",
    "            break\n",
    "    else:\n",
    "        print(f'Valor {target} no encontrado')\n",
    "    \n",
    "    print(f'Tiempo: {total_time:.4f}s')\n",
    "    print(f'Cores utilizados: {n_cores}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe120ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño de la lista: 10,000,000\n",
      "Valor a buscar: 8,888,888\n",
      "Cores disponibles: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m1\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "    from multiprocessing.spawn import spawn_main; \u001b[31mspawn_main\u001b[0m\u001b[1;31m(tracker_fd=85, pipe_handle=89)\u001b[0m\n",
      "                                                  \u001b[31m~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "  File \u001b[35m\"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m122\u001b[0m, in \u001b[35mspawn_main\u001b[0m\n",
      "    exitcode = _main(fd, parent_sentinel)\n",
      "  File \u001b[35m\"/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/spawn.py\"\u001b[0m, line \u001b[35m132\u001b[0m, in \u001b[35m_main\u001b[0m\n",
      "    self = reduction.pickle.load(from_parent)\n",
      "\u001b[1;35mAttributeError\u001b[0m: \u001b[35mCan't get attribute 'worker' on <module '__main__' (<class '_frozen_importlib.BuiltinImporter'>)>\u001b[0m\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     12\u001b[39m datos = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(SIZE))\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Ejecutar función general\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43mparallel_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdatos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTARGET\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCORES\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mparallel_search\u001b[39m\u001b[34m(data, target, n_cores)\u001b[39m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m chunk_data \u001b[38;5;129;01min\u001b[39;00m chunks:\n\u001b[32m     36\u001b[39m     p = mp.Process(target=worker, args=(chunk_data, queue))\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     \u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m     processes.append(p)\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Esperar a que terminen\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/process.py:121\u001b[39m, in \u001b[36mBaseProcess.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _current_process._config.get(\u001b[33m'\u001b[39m\u001b[33mdaemon\u001b[39m\u001b[33m'\u001b[39m), \\\n\u001b[32m    119\u001b[39m        \u001b[33m'\u001b[39m\u001b[33mdaemonic processes are not allowed to have children\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    120\u001b[39m _cleanup()\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28mself\u001b[39m._popen = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[38;5;28mself\u001b[39m._sentinel = \u001b[38;5;28mself\u001b[39m._popen.sentinel\n\u001b[32m    123\u001b[39m \u001b[38;5;66;03m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[32m    124\u001b[39m \u001b[38;5;66;03m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/context.py:224\u001b[39m, in \u001b[36mProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    222\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m--> \u001b[39m\u001b[32m224\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mProcess\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_Popen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/context.py:289\u001b[39m, in \u001b[36mSpawnProcess._Popen\u001b[39m\u001b[34m(process_obj)\u001b[39m\n\u001b[32m    286\u001b[39m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[32m    287\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_Popen\u001b[39m(process_obj):\n\u001b[32m    288\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpopen_spawn_posix\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Popen\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/popen_spawn_posix.py:32\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, process_obj):\n\u001b[32m     31\u001b[39m     \u001b[38;5;28mself\u001b[39m._fds = []\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/popen_fork.py:20\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28mself\u001b[39m.returncode = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mself\u001b[39m.finalizer = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_launch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocess_obj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/popen_spawn_posix.py:62\u001b[39m, in \u001b[36mPopen._launch\u001b[39m\u001b[34m(self, process_obj)\u001b[39m\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.sentinel = parent_r\n\u001b[32m     61\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(parent_w, \u001b[33m'\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m'\u001b[39m, closefd=\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m---> \u001b[39m\u001b[32m62\u001b[39m         \u001b[43mf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetbuffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m     64\u001b[39m     fds_to_close = []\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "SIZE = 10000000 # 10M\n",
    "TARGET = 8888888\n",
    "CORES = mp.cpu_count() # Usar todos los cores disponibles\n",
    "\n",
    "print(f'\\nTamaño de la lista: {SIZE:,}')\n",
    "print(f'Valor a buscar: {TARGET:,}')\n",
    "print(f'Cores disponibles: {CORES}')\n",
    "\n",
    "# Generar datos\n",
    "datos = list(range(SIZE))\n",
    "\n",
    "# Ejecutar función general\n",
    "parallel_search(datos, TARGET, CORES)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c221131",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
